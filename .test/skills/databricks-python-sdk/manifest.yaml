skill:
  name: "databricks-python-sdk"
  source_path: ".claude/skills/databricks-python-sdk"
  description: "Databricks SDK, Databricks Connect, CLI, and REST API guidance"

evaluation:
  datasets:
    - path: ground_truth.yaml
      type: yaml

# Scorer configuration
scorers:
  # Built-in deterministic scorers to enable
  enabled:
    - python_syntax
    - pattern_adherence
    - no_hallucinated_apis
    - expected_facts_present

  # LLM-based scorers
  llm_scorers:
    - Safety
    - guidelines_from_expectations  # Dynamic from YAML expectations.guidelines

  # Default guidelines (used when test case has no guidelines)
  default_guidelines:
    - "Response must address the user's SDK/API request completely"
    - "Code examples must be syntactically correct Python"
    - "Must use modern Databricks SDK APIs (databricks.sdk, not legacy)"
    - "Async applications must wrap SDK calls with asyncio.to_thread()"
    - "Must handle pagination correctly for list operations"
    - "Error handling should use databricks.sdk.errors exceptions"

# Trace expectations for session evaluation
trace_expectations:
  tool_usage:
    forbidden:
      - "mcp__databricks__execute_sql"  # SDK skill shouldn't use SQL execution
    preferred:
      - "WebFetch"  # Should reference SDK documentation when uncertain

  patterns:
    must_include:
      - "databricks.sdk"
      - "WorkspaceClient"
    must_exclude:
      - "from pyspark.dbutils"  # Legacy pattern
      - "dbutils.notebook.run"  # Legacy pattern in SDK context

quality_gates:
  syntax_valid: 1.0
  pattern_adherence: 0.9
  no_hallucinated_apis: 1.0
  execution_success: 0.8
